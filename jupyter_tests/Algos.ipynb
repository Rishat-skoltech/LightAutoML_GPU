{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029b135b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8919bccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "from time import perf_counter\n",
    "\n",
    "from dask.distributed import Client\n",
    "from dask_cuda import LocalCUDACluster\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask_cudf\n",
    "import cudf\n",
    "import cupy as cp\n",
    "import random\n",
    "\n",
    "from lightautoml.tasks import Task\n",
    "from lightautoml.reader.cudf_reader import CudfReader\n",
    "from lightautoml.reader.daskcudf_reader import DaskCudfReader\n",
    "from lightautoml.reader.base import PandasToPandasReader\n",
    "\n",
    "# Standard python libraries\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "logging.basicConfig(format='[%(asctime)s] (%(levelname)s): %(message)s', level=logging.INFO)\n",
    "\n",
    "# Installed libraries\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "# Imports from our package\n",
    "from lightautoml.automl.base import AutoML\n",
    "\n",
    "from lightautoml.pipelines.features.lgb_pipeline_gpu import LGBSimpleFeatures_gpu, LGBAdvancedPipeline_gpu\n",
    "from lightautoml.pipelines.features.linear_pipeline_gpu import LinearFeatures_gpu\n",
    "from lightautoml.ml_algo.boost_xgb_gpu import BoostXGB_dask\n",
    "\n",
    "from lightautoml.ml_algo.linear_gpu import LinearLBFGS_gpu\n",
    "from lightautoml.ml_algo.tuning.optuna import OptunaTuner\n",
    "\n",
    "from lightautoml.pipelines.ml.base import MLPipeline\n",
    "from lightautoml.pipelines.selection.importance_based import ModelBasedImportanceEstimator, ImportanceCutoffSelector\n",
    "\n",
    "from lightautoml.automl.blend_gpu import WeightedBlender_gpu\n",
    "\n",
    "from lightautoml.utils.profiler import Profiler\n",
    "from lightautoml.utils.timer import PipelineTimer\n",
    "\n",
    "from numba import jit\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8345962",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDS_CHARS = np.array(list(string.ascii_letters + string.digits),\n",
    "                       dtype=(np.str_, 1))\n",
    "\n",
    "N_THREADS = 8 # threads cnt for lgbm and linear models\n",
    "N_FOLDS = 5 # folds cnt for AutoML\n",
    "RANDOM_STATE = 42 # fixed random state for various reasons\n",
    "TEST_SIZE = 0.2 # Test size for metric check\n",
    "TIMEOUT = 600 # Time in seconds for automl run\n",
    "TARGET_NAME = 'target' # Target column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b28eeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def gen_cols(n_cols):\n",
    "    cols = [\"\"]*n_cols\n",
    "    for i in range(n_cols):\n",
    "        cols[i] = \"col_\" + str(i)\n",
    "    return cols\n",
    "\n",
    "def gen_string_data(n, n_str):\n",
    "    string_db = [\"algorithm\", \"analog\", \"app\", \"application\", \"array\",\n",
    "                 \"backup\", \"bandwidth\", \"binary\", \"bit\", \"byte\"]#,\n",
    "                 #\"bitmap\", \"blog\", \"bookmark\", \"boot\", \"broadband\",\n",
    "                 #\"browser\" , \"buffer\", \"bug\"]\n",
    "    inds = np.random.randint(0, len(string_db), (n, n_str))\n",
    "    output = np.empty(inds.shape, dtype=object)\n",
    "    for i in range(inds.shape[0]):\n",
    "        for j in range(inds.shape[1]):\n",
    "            output[i][j] = string_db[inds[i][j]]\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99a732e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(n, n_num, n_cat, n_date, n_str, max_n_cat):\n",
    "    print(\"Generating dummy data\")\n",
    "    n_cols = n_num+n_cat+n_str+n_date\n",
    "    cols = gen_cols(n_cols)\n",
    "    data = np.random.random((n, n_num))*100-50\n",
    "\n",
    "    category_data = np.random.randint(0, np.random.randint(1,max_n_cat), (n, n_cat))\n",
    "    string_data = gen_string_data(n, n_str)\n",
    "\n",
    "    string_data = np.reshape(string_data, (n, n_str))\n",
    "\n",
    "    date_data = np.random.randint(0, 1000,\n",
    "                               (n, n_date)).astype(np.dtype(\"timedelta64[D]\")) \\\n",
    "                               + np.datetime64(\"2018-01-01\")\n",
    "\n",
    "    data = pd.DataFrame(data, columns = cols[:n_num]).astype('f')\n",
    "    \n",
    "    ix = [(row, col) for row in range(data.shape[0]) for col in range(data.shape[1])]\n",
    "    for row, col in random.sample(ix, int(round(.1*len(ix)))):\n",
    "        data.iat[row, col] = np.nan\n",
    "    \n",
    "    nn = len(data.columns)\n",
    "    for i in range(n_cat):\n",
    "        data[cols[nn+i]] = pd.Series(category_data[:,i]).astype('f')\n",
    "    nn = len(data.columns)\n",
    "    for i in range(n_str):\n",
    "        data[cols[nn+i]] = pd.Series(string_data[:,i]).astype(object)\n",
    "    nn = len(data.columns)\n",
    "    for i in range(n_date):\n",
    "        data[cols[nn+i]] = pd.Series(date_data[:,i])\n",
    "        \n",
    "    data['target'] = pd.Series(np.random.randint(0, 4, n)).astype('i')\n",
    "\n",
    "    print(\"Shape of the dummy data:\", data.shape)\n",
    "    print(\"Size of the dummy data:\",\n",
    "          round(data.memory_usage(deep=True).sum()/1024./1024.,4), \"MB.\")\n",
    "    return 'target', cols, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2394f714",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = LocalCUDACluster(rmm_managed_memory=True, CUDA_VISIBLE_DEVICES=\"0\",\n",
    "                               protocol=\"ucx\", enable_nvlink=True,\n",
    "                               memory_limit=\"8GB\")\n",
    "print(\"dashboard:\", cluster.dashboard_link)\n",
    "client = Client(cluster)\n",
    "client.run(cudf.set_allocator, \"managed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7ea5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "target, _, data = generate_data(n=40, n_num=3, n_cat=2, n_date=5,\n",
    "                                    n_str=5, max_n_cat=10)\n",
    "                                    \n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7368501a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(data, \n",
    "                                         test_size=TEST_SIZE, \n",
    "                                         stratify=data[TARGET_NAME], \n",
    "                                         random_state=RANDOM_STATE)\n",
    "    \n",
    "cudf_data = cudf.DataFrame.from_pandas(data, nan_as_null=False)\n",
    "    \n",
    "train_cudf = cudf.DataFrame.from_pandas(train_data, nan_as_null=False)\n",
    "test_cudf = cudf.DataFrame.from_pandas(test_data, nan_as_null=False)\n",
    "    \n",
    "daskcudf_data = dask_cudf.from_cudf(cudf_data, npartitions=1)\n",
    "    \n",
    "train_daskcudf = dask_cudf.from_cudf(train_cudf, npartitions=1)\n",
    "test_daskcudf = dask_cudf.from_cudf(test_cudf, npartitions=1)\n",
    "    \n",
    "np.random.seed(RANDOM_STATE)\n",
    "torch.set_num_threads(N_THREADS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51dbb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "timer = PipelineTimer(600, mode=2)\n",
    "timer_gbm = timer.get_task_timer('gbm') # Get task timer from pipeline timer \n",
    "feat_sel_0 = LGBSimpleFeatures_gpu()\n",
    "mod_sel_0 = BoostXGB_dask(client, timer=timer_gbm)\n",
    "imp_sel_0 = ModelBasedImportanceEstimator()\n",
    "selector_0 = ImportanceCutoffSelector(feat_sel_0, mod_sel_0, imp_sel_0, cutoff=0, )\n",
    "feats_gbm_0 = LGBAdvancedPipeline_gpu(top_intersections=4, \n",
    "                                  output_categories=True, \n",
    "                                  feats_imp=imp_sel_0)\n",
    "\n",
    "timer_gbm_0 = timer.get_task_timer('gbm')\n",
    "timer_gbm_1 = timer.get_task_timer('gbm')\n",
    "    \n",
    "gbm_0 = BoostXGB_dask(client, timer=timer_gbm_0)\n",
    "gbm_1 = BoostXGB_dask(client, timer=timer_gbm_1)\n",
    "\n",
    "tuner_0 = OptunaTuner(n_trials=20, timeout=30, fit_on_holdout=True)\n",
    "gbm_lvl0 = MLPipeline([\n",
    "        (gbm_0, tuner_0),\n",
    "        gbm_1\n",
    "    ],\n",
    "    pre_selection=selector_0,\n",
    "    features_pipeline=feats_gbm_0, \n",
    "    post_selection=None\n",
    ")\n",
    "    \n",
    "feats_reg_0 = LinearFeatures_gpu(output_categories=True, \n",
    "                         sparse_ohe='auto')\n",
    "\n",
    "timer_reg = timer.get_task_timer('reg')\n",
    "reg_0 = LinearLBFGS_gpu(timer=timer_reg)\n",
    "reg_lvl0 = MLPipeline([\n",
    "        reg_0\n",
    "    ],\n",
    "    pre_selection=None,\n",
    "    features_pipeline=feats_reg_0, \n",
    "    post_selection=None\n",
    ")\n",
    "task = Task('multiclass', metric = 'accuracy', device='mgpu')\n",
    "\n",
    "reader = DaskCudfReader(task = task, samples = None, max_nan_rate = 1,\n",
    "                          max_constant_rate = 1, advanced_roles = True,\n",
    "                          drop_score_co = -1, n_jobs = 1, compute=True)\n",
    "                          \n",
    "blender = WeightedBlender_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a19378a",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = AutoML(reader=reader, levels=[\n",
    "    [reg_lvl0]#[gbm_lvl0, reg_lvl0]\n",
    "], timer=timer, blender=blender, skip_conn=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e9cab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_pred = automl.fit_predict(train_daskcudf,\n",
    "                              roles={'target': TARGET_NAME})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdbca4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info('oof_pred:\\n{}\\nShape = {}'.format(oof_pred.data.compute(), oof_pred.shape))\n",
    "    \n",
    "test_pred = automl.predict(test_daskcudf)\n",
    "print(type(test_pred))\n",
    "logging.debug('Prediction for test data:\\n{}\\nShape = {}'\n",
    "          .format(test_pred, test_pred.shape))\n",
    "\n",
    "logging.info('Check scores...')\n",
    "logging.info('OOF score: {}'.format(log_loss(train_daskcudf[TARGET_NAME].compute().values.get(), oof_pred.data.compute().values.get())))\n",
    "logging.info('TEST score: {}'.format(log_loss(test_daskcudf[TARGET_NAME].compute().values.get(), test_pred.data.compute().values.get())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35b9b1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
